#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… IP Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø§ Ø³ÛŒØ³ØªÙ… fallback
"""

import yaml
import requests
from datetime import datetime, timedelta
import os
import sys
import socket
import time
import base64
import json
import re
import random
import threading
from urllib.parse import urlparse, parse_qs
from bs4 import BeautifulSoup
from typing import List, Dict, Any, Tuple, Set, Optional

class Logger:
    """Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ¶Ø§ÛŒ Ø¯ÛŒØ³Ú©"""
    def __init__(self, log_dir="output/logs"):
        self.log_dir = log_dir
        os.makedirs(self.log_dir, exist_ok=True)
        
        # Ø¢Ù…Ø§Ø±Ù‡Ø§
        self.stats = {
            'total_proxies_received': 0,
            'iranian_proxies': 0,
            'non_iranian_proxies': 0,
            'active_proxies_found': 0,
            'inactive_proxies': 0,
            'duplicates_found': 0,
            'proxies_added': 0,
            'proxies_removed': 0,
            'ip_checks': 0,
            'ip_cache_hits': 0,
            'api_requests': 0,
            'api_failures': 0,
            'sources_used': 0,
            'sources_failed': 0,
            'old_logs_deleted': 0
        }
        
        # Ø­Ø°Ù Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² 2 Ù‡ÙØªÙ‡
        self.clean_old_logs()
        
        # ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ø¨Ø§ timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = os.path.join(self.log_dir, f"proxy_update_{timestamp}.log")
        self.console_log_file = os.path.join(self.log_dir, "latest.log")
        
        # Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        self.log_fd = open(self.log_file, 'w', encoding='utf-8')
        self.console_log_fd = open(self.console_log_file, 'w', encoding='utf-8')
    
    def clean_old_logs(self):
        """Ø­Ø°Ù Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² 2 Ù‡ÙØªÙ‡"""
        cutoff_date = datetime.now() - timedelta(days=14)
        deleted_count = 0
        
        if os.path.exists(self.log_dir):
            for filename in os.listdir(self.log_dir):
                if filename.endswith('.log'):
                    file_path = os.path.join(self.log_dir, filename)
                    
                    try:
                        if filename.startswith('proxy_update_'):
                            date_str = filename[13:21]  # YYYYMMDD
                            file_date = datetime.strptime(date_str, "%Y%m%d")
                            
                            if file_date < cutoff_date:
                                os.remove(file_path)
                                deleted_count += 1
                    except:
                        file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                        if file_mtime < cutoff_date:
                            os.remove(file_path)
                            deleted_count += 1
        
        self.stats['old_logs_deleted'] = deleted_count
        if deleted_count > 0:
            print(f"ğŸ—‘ï¸  Ø­Ø°Ù {deleted_count} ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ù‚Ø¯ÛŒÙ…ÛŒ (Ø¨ÛŒØ´ØªØ± Ø§Ø² 2 Ù‡ÙØªÙ‡)")
    
    def log(self, message: str, level: str = "INFO"):
        """Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯ Ø¯Ø± ÙØ§ÛŒÙ„ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        formatted_message = f"[{timestamp}] [{level}] {message}"
        
        # Ú†Ø§Ù¾ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„
        print(formatted_message)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        self.log_fd.write(formatted_message + "\n")
        self.console_log_fd.write(formatted_message + "\n")
        
        # flush Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø°Ø®ÛŒØ±Ù‡
        self.log_fd.flush()
        self.console_log_fd.flush()
    
    def update_stat(self, stat_name: str, value: int = 1):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±"""
        if stat_name in self.stats:
            self.stats[stat_name] += value
    
    def print_stats(self):
        """Ú†Ø§Ù¾ Ø¢Ù…Ø§Ø± Ú©Ø§Ù…Ù„"""
        self.log("\n" + "="*80, "STATS")
        self.log("ğŸ“Š Ø¢Ù…Ø§Ø± Ú©Ø§Ù…Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ", "STATS")
        self.log("="*80, "STATS")
        
        self.log(f"ğŸ“¥ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹:", "STATS")
        self.log(f"   â€¢ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: {self.stats['sources_used']}", "STATS")
        self.log(f"   â€¢ Ù…Ù†Ø§Ø¨Ø¹ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡: {self.stats['sources_failed']}", "STATS")
        self.log(f"   â€¢ Ú©Ù„ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ: {self.stats['total_proxies_received']:,}", "STATS")
        self.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: {self.stats['iranian_proxies']:,}", "STATS")
        self.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø§ÛŒØ±Ø§Ù†ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {self.stats['non_iranian_proxies']:,}", "STATS")
        
        self.log(f"\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª:", "STATS")
        self.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„: {self.stats['active_proxies_found']:,}", "STATS")
        self.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„: {self.stats['inactive_proxies']:,}", "STATS")
        
        self.log(f"\nğŸ”„ Ù¾Ø±Ø¯Ø§Ø²Ø´:", "STATS")
        self.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡: {self.stats['proxies_added']:,}", "STATS")
        self.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡ (Ù‚Ø¯ÛŒÙ…ÛŒ): {self.stats['proxies_removed']:,}", "STATS")
        self.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ: {self.stats['duplicates_found']:,}", "STATS")
        
        self.log(f"\nğŸŒ Ø¨Ø±Ø±Ø³ÛŒ IP:", "STATS")
        self.log(f"   â€¢ Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ IP Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡: {self.stats['ip_checks']:,}", "STATS")
        self.log(f"   â€¢ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ IP: {self.stats['ip_cache_hits']:,}", "STATS")
        self.log(f"   â€¢ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ API: {self.stats['api_requests']:,}", "STATS")
        self.log(f"   â€¢ Ø®Ø·Ø§Ù‡Ø§ÛŒ API: {self.stats['api_failures']:,}", "STATS")
        
        self.log(f"\nğŸ—‘ï¸  Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§:", "STATS")
        self.log(f"   â€¢ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {self.stats['old_logs_deleted']}", "STATS")
        
        self.log("="*80, "STATS")
    
    def close(self):
        """Ø¨Ø³ØªÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯"""
        self.log_fd.close()
        self.console_log_fd.close()

class IranProxyManager:
    def __init__(self, config_path: str = "output/config.yaml"):
        self.config_path = config_path
        self.logger = Logger()
        self.config = self.load_config()
        self.failed_sources = []
        self.ip_cache = {}
        self.lock = threading.Lock()
        
        # Ù…Ù†Ø§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
        self.SOURCES = [
            ("https://raw.githubusercontent.com/mahdibland/V2RayAggregator/master/sub/splitted/vmess.txt", "vmess", "github-vmess"),
            ("https://raw.githubusercontent.com/mahdibland/V2RayAggregator/master/sub/splitted/vless.txt", "vless", "github-vless"),
            ("https://raw.githubusercontent.com/mahdibland/V2RayAggregator/master/sub/splitted/ss.txt", "ss", "github-ss"),
            ("https://raw.githubusercontent.com/iranxray/hope/main/singbox", "vless", "github-hope"),
            ("https://raw.githubusercontent.com/yebekhe/TelegramV2rayCollector/main/singbox", "vless", "github-telegram"),
            ("https://raw.githubusercontent.com/mahdibland/ShadowsocksAggregator/master/sub/sb", "ss", "github-ss-aggr"),
            ("https://raw.githubusercontent.com/freefq/free/master/v2", "vmess", "github-freefq"),
            ("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=socks5&country=IR", "socks5", "proxyscrape-socks5"),
            ("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&country=IR", "http", "proxyscrape-http"),
            ("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=https&country=IR", "http", "proxyscrape-https"),
            ("https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt", "socks5", "github-socks5"),
            ("https://raw.githubusercontent.com/hookzof/socks5_list/master/proxy.txt", "socks5", "github-hookzof"),
            ("https://raw.githubusercontent.com/peasoft/NoMoreWalls/master/list.txt", "mixed", "github-nowalls"),
            ("https://raw.githubusercontent.com/BlueSkyXN/9.DDFHP/main/1", "mixed", "github-ddfhp"),
            ("https://proxyhub.me/en/ir-http-proxy-list.html", "html-http", "proxyhub-http"),
            ("https://proxyhub.me/en/ir-sock5-proxy-list.html", "html-socks5", "proxyhub-socks5"),
            ("https://www.proxydocker.com/en/socks5-list/country/Iran", "html-socks5", "proxydocker-socks5"),
            ("https://www.proxydocker.com/en/proxylist/search?need=all&type=http-https&anonymity=all&port=&country=Iran&city=&state=all", "html-http", "proxydocker-http"),
            ("https://www.freeproxy.world/?type=http&anonymity=&country=IR", "html-http", "freeproxy-http"),
            ("https://www.freeproxy.world/?type=socks5&anonymity=&country=IR", "html-socks5", "freeproxy-socks5"),
            # Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ
            ("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=10000&country=all", "http", "emergency-http"),
            ("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=socks5&timeout=10000&country=all", "socks5", "emergency-socks5"),
            ("https://raw.githubusercontent.com/freefq/free/master/v2", "vmess", "emergency-vmess"),
        ]
        
        # Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ IP
        self.IP_CHECK_SERVICES = [
            {'name': 'ip-api.com', 'url': 'http://ip-api.com/json/{ip}?fields=status,countryCode,query', 'field': 'countryCode', 'timeout': 3, 'max_retries': 2},
            {'name': 'ipapi.co', 'url': 'https://ipapi.co/{ip}/country/', 'field': 'text', 'timeout': 3, 'max_retries': 2},
            {'name': 'ipinfo.io', 'url': 'https://ipinfo.io/{ip}/country', 'field': 'text', 'timeout': 3, 'max_retries': 2},
        ]
        
        # User-Agent Ù‡Ø§ÛŒ Ù…ØªÙ†ÙˆØ¹
        self.USER_AGENTS = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/122.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Googlebot/2.1 (+http://www.google.com/bot.html)",
            "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)",
            "FacebookExternalHit/1.1 (+http://www.facebook.com/externalhit_uatext.php)",
            "DuckDuckBot/1.0; (+http://duckduckgo.com/duckduckbot.html)",
            "Twitterbot/1.0",
            "Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1",
            "curl/7.88.1",
            "Wget/1.21.4",
        ]
    
    def __del__(self):
        self.logger.close()
    
    def load_config(self) -> Dict[str, Any]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if content.strip():
                        config = yaml.safe_load(content)
                        if config and 'proxies' in config:
                            self.logger.log(f"ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø§ {len(config['proxies'])} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                            return config
            self.logger.log("ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯...")
            return {"proxies": [], "metadata": {}}
        except Exception as e:
            self.logger.log(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯: {e}", "ERROR")
            return {"proxies": [], "metadata": {}}
    
    def save_config(self):
        """Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø§ ØªØµØ­ÛŒØ­ alterId"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            
            cleaned_proxies = []
            for proxy in self.config.get('proxies', []):
                if not all(key in proxy for key in ['server', 'port', 'type', 'added_date']):
                    continue
                
                cleaned_proxy = {
                    'name': proxy.get('name', f"{proxy['server']}:{proxy['port']}"),
                    'type': str(proxy['type']),
                    'server': str(proxy['server']),
                    'port': int(proxy['port']),
                    'added_date': str(proxy['added_date']),
                    'last_checked': str(proxy.get('last_checked', proxy['added_date'])),
                    'is_active': bool(proxy.get('is_active', True)),
                    'country': str(proxy.get('country', 'IR')),
                }
                
                # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
                optional_fields = ['ping', 'source', 'uuid', 'cipher', 'password', 'network', 'tls']
                for field in optional_fields:
                    if field in proxy:
                        cleaned_proxy[field] = proxy[field]
                
                # ØªØµØ­ÛŒØ­ alterld Ø¨Ù‡ alterId (Ø­Ù„ Ù…Ø´Ú©Ù„ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¯Ø±ÙˆÛŒØ¯)
                if 'alterld' in proxy:  # Ø§Ø´ØªØ¨Ø§Ù‡ ØªØ§ÛŒÙ¾ÛŒ Ø¨Ø§ Ø­Ø±Ù L
                    cleaned_proxy['alterId'] = proxy['alterld']
                elif 'alterId' in proxy:  # Ø¯Ø±Ø³Øª
                    cleaned_proxy['alterId'] = proxy['alterId']
                elif cleaned_proxy['type'] == 'vmess':
                    cleaned_proxy['alterId'] = 0  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                
                # Ø³Ø§ÛŒØ± ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ
                if 'ws-opts' in proxy:
                    cleaned_proxy['ws-opts'] = proxy['ws-opts']
                
                cleaned_proxies.append(cleaned_proxy)
            
            metadata = {
                'total_count': len(cleaned_proxies),
                'active_count': len([p for p in cleaned_proxies if p['is_active']]),
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'retention_days': 3,
                'min_proxies': 50,
                'sources_used': len(self.SOURCES),
                'log_retention_days': 14,
                'log_file': self.logger.log_file
            }
            
            final_config = {'proxies': cleaned_proxies, 'metadata': metadata}
            
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(final_config, f, 
                         default_flow_style=False, 
                         allow_unicode=True, 
                         sort_keys=False,
                         indent=2)
            
            self.logger.log(f"ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ ({len(cleaned_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ)")
            return True
        except Exception as e:
            self.logger.log(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ù†ÙÛŒÚ¯: {e}", "ERROR")
            return False
    
    def is_alive(self, ip: str, port: int, timeout: int = 5) -> Tuple[bool, int]:
        """Ø¨Ø±Ø±Ø³ÛŒ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ù¾Ø±ÙˆÚ©Ø³ÛŒ"""
        try:
            start = time.time()
            s = socket.create_connection((ip, port), timeout=timeout)
            s.close()
            ping = int((time.time() - start) * 1000)
            if ping > 0:
                self.logger.update_stat('active_proxies_found')
            return True, ping
        except:
            self.logger.update_stat('inactive_proxies')
            return False, 0
    
    def is_private_ip(self, ip: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ IP Ø®ØµÙˆØµÛŒ"""
        private_ranges = [
            ('10.0.0.0', '10.255.255.255'),
            ('172.16.0.0', '172.31.255.255'),
            ('192.168.0.0', '192.168.255.255'),
            ('127.0.0.0', '127.255.255.255'),
            ('169.254.0.0', '169.254.255.255'),
        ]
        
        ip_int = self.ip_to_int(ip)
        for start, end in private_ranges:
            if ip_int >= self.ip_to_int(start) and ip_int <= self.ip_to_int(end):
                return True
        return False
    
    def ip_to_int(self, ip: str) -> int:
        """ØªØ¨Ø¯ÛŒÙ„ IP Ø¨Ù‡ Ø¹Ø¯Ø¯ ØµØ­ÛŒØ­"""
        parts = ip.split('.')
        return (int(parts[0]) << 24) + (int(parts[1]) << 16) + (int(parts[2]) << 8) + int(parts[3])
    
    def check_ip_service(self, service: dict, ip: str) -> Optional[str]:
        """Ø¨Ø±Ø±Ø³ÛŒ IP Ø¨Ø§ ÛŒÚ© Ø³Ø±ÙˆÛŒØ³ Ø®Ø§Øµ"""
        self.logger.update_stat('api_requests')
        
        for attempt in range(service['max_retries']):
            try:
                url = service['url'].format(ip=ip)
                headers = self.get_headers()
                
                response = requests.get(url, timeout=service['timeout'], headers=headers)
                
                if response.status_code == 200:
                    if service['field'] == 'text':
                        country = response.text.strip()
                        if len(country) == 2:
                            return country
                    else:
                        data = response.json()
                        if service['field'] in data:
                            country = data[service['field']]
                            if country and len(country) == 2:
                                return country
                
                if response.status_code == 429:
                    time.sleep(3)
                    
            except requests.exceptions.Timeout:
                continue
            except requests.exceptions.ConnectionError:
                continue
            except Exception:
                continue
        
        self.logger.update_stat('api_failures')
        return None
    
    def get_headers(self):
        """Ø§ÛŒØ¬Ø§Ø¯ headers Ø¨Ø§ User-Agent ØªØµØ§Ø¯ÙÛŒ"""
        return {
            "User-Agent": random.choice(self.USER_AGENTS),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Cache-Control": "max-age=0",
            "Referer": "https://www.google.com/"
        }
    
    def check_ip_country(self, ip: str) -> Optional[str]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´ÙˆØ± IP Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø§ fallback"""
        with self.lock:
            if ip in self.ip_cache:
                self.logger.update_stat('ip_cache_hits')
                return self.ip_cache[ip]
        
        self.logger.update_stat('ip_checks')
        
        if self.is_private_ip(ip):
            with self.lock:
                self.ip_cache[ip] = None
            return None
        
        country = None
        
        for service in self.IP_CHECK_SERVICES:
            result = self.check_ip_service(service, ip)
            if result:
                country = result
                break
        
        with self.lock:
            self.ip_cache[ip] = country
        
        return country
    
    def ip_is_ir(self, ip: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø¨ÙˆØ¯Ù† IP"""
        country = self.check_ip_country(ip)
        is_iran = country == 'IR'
        
        if country and not is_iran:
            self.logger.update_stat('non_iranian_proxies')
        
        return is_iran
    
    def parse_ss(self, url: str) -> Dict[str, Any]:
        """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú© Shadowsocks"""
        try:
            url = url[5:]
            if "#" in url:
                url, tag = url.split("#", 1)
            else:
                tag = "ss"
            
            if "@" not in url:
                url = base64.b64decode(url + "==").decode()
                method, rest = url.split(":", 1)
                password, serverport = rest.split("@")
                server, port = serverport.split(":")
            else:
                userinfo, serverinfo = url.split("@")
                method, password = base64.b64decode(userinfo + "==").decode().split(":")
                server, port = serverinfo.split(":")
            
            return {
                "name": tag,
                "type": "ss",
                "server": server,
                "port": int(port),
                "cipher": method,
                "password": password,
                "udp": True
            }
        except:
            return None
    
    def parse_vless(self, url: str) -> Dict[str, Any]:
        """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú© VLESS"""
        try:
            parsed = urlparse(url)
            q = parse_qs(parsed.query)
            
            return {
                "name": parsed.fragment or f"{parsed.hostname}:{parsed.port}",
                "type": "vless",
                "server": parsed.hostname,
                "port": int(parsed.port),
                "uuid": parsed.username,
                "tls": q.get("security", ["none"])[0] == "tls",
                "udp": True,
                "network": q.get("type", ["tcp"])[0],
                "ws-opts": {
                    "path": q.get("path", ["/"])[0],
                    "headers": {"Host": q.get("host", [""])[0]}
                } if q.get("type", ["tcp"])[0] == "ws" else {}
            }
        except:
            return None
    
    def fetch_html_proxies(self, url: str, proxy_type: str, source_name: str) -> List[Tuple[str, str, str]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ø² ØµÙØ­Ø§Øª HTML"""
        proxies = []
        try:
            headers = self.get_headers()
            
            time.sleep(random.uniform(2, 5))
            
            res = requests.get(url, headers=headers, timeout=20)
            res.raise_for_status()
            soup = BeautifulSoup(res.text, "html.parser")

            if "freeproxy.world" in url:
                table = soup.find("table")
                rows = table.find_all("tr")[1:] if table else []
                for row in rows:
                    cols = row.find_all("td")
                    if len(cols) < 2:
                        continue
                    ip = cols[0].get_text(strip=True)
                    port = cols[1].get_text(strip=True)
                    if ip and port:
                        proxies.append((ip, port, "socks5" if "socks5" in proxy_type else "http"))
            else:
                rows = soup.find_all("tr")
                for row in rows:
                    cols = row.find_all("td")
                    if len(cols) < 2:
                        continue
                    ip, port = cols[0].text.strip(), cols[1].text.strip()
                    if ip and port and re.match(r"^\d+\.\d+\.\d+\.\d+$", ip):
                        proxies.append((ip, port, "socks5" if "socks5" in proxy_type else "http"))

            return proxies
        except Exception:
            return []
    
    def fetch_source_proxies(self, url: str, ptype: str, source_name: str, source_index: int, total_sources: int) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ø² ÛŒÚ© Ù…Ù†Ø¨Ø¹ Ø®Ø§Øµ"""
        proxies = []
        
        # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ¹Ù„ÛŒ
        current_total = self.logger.stats['total_proxies_received']
        current_iranian = self.logger.stats['iranian_proxies']
        self.logger.log(f"[{source_index}/{total_sources}] ğŸ” Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² {source_name}", "INFO")
        self.logger.log(f"   ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ: [{current_iranian}/{current_total}]", "DEBUG")
        
        # ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯
        for attempt in range(3):
            try:
                self.logger.update_stat('sources_used')
                
                headers = self.get_headers()
                
                delay = random.uniform(2, 4) if attempt > 0 else random.uniform(1, 2)
                time.sleep(delay)
                
                response = requests.get(url, timeout=25, headers=headers)
                
                if response.status_code == 200:
                    break
                elif response.status_code == 403:
                    self.logger.log(f"   âš ï¸ Ø¯Ø³ØªØ±Ø³ÛŒ Ù…Ù…Ù†ÙˆØ¹ (403) - ØªÙ„Ø§Ø´ {attempt+1}/3", "WARNING")
                    if attempt < 2:
                        time.sleep(random.uniform(5, 8))
                        continue
                    else:
                        self.logger.log(f"   âŒ Ø¨Ø¹Ø¯ Ø§Ø² Û³ ØªÙ„Ø§Ø´ Ù…ÙˆÙÙ‚ Ù†Ø´Ø¯ÛŒÙ…", "ERROR")
                        self.failed_sources.append(url)
                        self.logger.update_stat('sources_failed')
                        return []
                else:
                    if attempt < 2:
                        time.sleep(3)
                        continue
                    else:
                        self.failed_sources.append(url)
                        self.logger.update_stat('sources_failed')
                        return []
                        
            except requests.exceptions.Timeout:
                if attempt < 2:
                    time.sleep(5)
                    continue
                else:
                    self.failed_sources.append(url)
                    self.logger.update_stat('sources_failed')
                    return []
            except Exception:
                if attempt < 2:
                    time.sleep(3)
                    continue
                else:
                    self.failed_sources.append(url)
                    self.logger.update_stat('sources_failed')
                    return []
        
        # Ø§Ú¯Ø± Ù…Ù†Ø¨Ø¹ HTML Ø§Ø³Øª
        if ptype.startswith("html-"):
            html_proxies = self.fetch_html_proxies(url, ptype, source_name)
            total_lines = len(html_proxies)
            self.logger.update_stat('total_proxies_received', total_lines)
            
            added_count = 0
            skipped_non_iran = 0
            
            for idx, (ip, port, proto) in enumerate(html_proxies, 1):
                # Ù†Ù…Ø§ÛŒØ´ Ù‡Ø± Ûµ Ù¾Ø±ÙˆÚ©Ø³ÛŒ
                if idx % 5 == 0:
                    current_total = self.logger.stats['total_proxies_received']
                    current_iranian = self.logger.stats['iranian_proxies']
                    self.logger.log(f"   ğŸ”„ [{source_index}/{total_sources}] | [{current_iranian}/{current_total}] - Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±ÙˆÚ©Ø³ÛŒ {idx}", "DEBUG")
                
                if not self.ip_is_ir(ip):
                    skipped_non_iran += 1
                    continue
                
                self.logger.update_stat('iranian_proxies')
                alive, ping = self.is_alive(ip, int(port))
                
                proxy_data = {
                    'name': f"{ip}:{port} ({ping}ms)" if alive else f"{ip}:{port}",
                    'type': proto,
                    'server': ip,
                    'port': int(port),
                    'added_date': datetime.now().strftime('%Y-%m-%d'),
                    'last_checked': datetime.now().strftime('%Y-%m-%d'),
                    'is_active': alive,
                    'country': 'IR',
                    'ping': ping if alive else 0,
                    'source': url,
                    'source_name': source_name
                }
                proxies.append(proxy_data)
                added_count += 1
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            current_total = self.logger.stats['total_proxies_received']
            current_iranian = self.logger.stats['iranian_proxies']
            self.logger.log(f"[{source_index}/{total_sources}] âœ… {source_name}: {added_count} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ", "INFO")
            self.logger.log(f"   ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ù†Ù‡Ø§ÛŒÛŒ: [{current_iranian}/{current_total}]", "DEBUG")
            
            return proxies
        
        # Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ù…ØªÙ†ÛŒ/API
        lines = response.text.strip().splitlines()
        total_lines = len(lines)
        self.logger.update_stat('total_proxies_received', total_lines)
        
        self.logger.log(f"   ğŸ“„ {total_lines} Ø®Ø· Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯", "DEBUG")
        
        added_count = 0
        skipped_non_iran = 0
        skipped_invalid = 0
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            if not line:
                continue
            
            # Ù†Ù…Ø§ÛŒØ´ Ù‡Ø± Û±Û° Ø®Ø·
            if line_num % 10 == 0:
                current_total = self.logger.stats['total_proxies_received']
                current_iranian = self.logger.stats['iranian_proxies']
                self.logger.log(f"   ğŸ”„ [{source_index}/{total_sources}] | [{current_iranian}/{current_total}] - Ø®Ø· {line_num}/{total_lines}", "DEBUG")
            
            try:
                # VMESS
                if ptype == "vmess" and line.startswith("vmess://"):
                    decoded = base64.b64decode(line[8:] + "==").decode()
                    conf = json.loads(decoded)
                    ip = conf.get("add")
                    port = conf.get("port")
                    
                    if not ip or not port:
                        skipped_invalid += 1
                        continue
                    
                    if not self.ip_is_ir(ip):
                        skipped_non_iran += 1
                        continue
                    
                    self.logger.update_stat('iranian_proxies')
                    alive, ping = self.is_alive(ip, port)
                    
                    proxy_data = {
                        'name': f"{ip}:{port} ({ping}ms)" if alive else f"{ip}:{port}",
                        'type': 'vmess',
                        'server': ip,
                        'port': int(port),
                        'uuid': conf.get("id"),
                        'alterId': int(conf.get("aid", 0)),
                        'cipher': conf.get("cipher", "auto"),
                        'tls': conf.get("tls") == "tls",
                        'network': conf.get("net", "tcp"),
                        'added_date': datetime.now().strftime('%Y-%m-%d'),
                        'last_checked': datetime.now().strftime('%Y-%m-%d'),
                        'is_active': alive,
                        'country': 'IR',
                        'ping': ping if alive else 0,
                        'source': url,
                        'source_name': source_name
                    }
                    
                    if conf.get("net") == "ws":
                        proxy_data["ws-opts"] = {
                            'path': conf.get("path", "/"),
                            'headers': {'Host': conf.get("host", "")}
                        }
                    
                    proxies.append(proxy_data)
                    added_count += 1
                
                # VLESS
                elif ptype == "vless" and line.startswith("vless://"):
                    conf = self.parse_vless(line)
                    if not conf:
                        skipped_invalid += 1
                        continue
                    
                    ip = conf.get("server")
                    
                    if not ip or not self.ip_is_ir(ip):
                        skipped_non_iran += 1
                        continue
                    
                    self.logger.update_stat('iranian_proxies')
                    alive, ping = self.is_alive(ip, conf["port"])
                    conf["added_date"] = datetime.now().strftime('%Y-%m-%d')
                    conf["last_checked"] = datetime.now().strftime('%Y-%m-%d')
                    conf["is_active"] = alive
                    conf["country"] = 'IR'
                    conf["ping"] = ping if alive else 0
                    conf["source"] = url
                    conf["source_name"] = source_name
                    conf["name"] = f"{conf['server']}:{conf['port']} ({ping}ms)" if alive else f"{conf['server']}:{conf['port']}"
                    
                    proxies.append(conf)
                    added_count += 1
                
                # Shadowsocks
                elif ptype == "ss" and line.startswith("ss://"):
                    conf = self.parse_ss(line)
                    if not conf:
                        skipped_invalid += 1
                        continue
                    
                    ip = conf.get("server")
                    
                    if not ip or not self.ip_is_ir(ip):
                        skipped_non_iran += 1
                        continue
                    
                    self.logger.update_stat('iranian_proxies')
                    alive, ping = self.is_alive(ip, conf["port"])
                    conf["added_date"] = datetime.now().strftime('%Y-%m-%d')
                    conf["last_checked"] = datetime.now().strftime('%Y-%m-%d')
                    conf["is_active"] = alive
                    conf["country"] = 'IR'
                    conf["ping"] = ping if alive else 0
                    conf["source"] = url
                    conf["source_name"] = source_name
                    conf["name"] = f"{conf['server']}:{conf['port']} ({ping}ms)" if alive else f"{conf['server']}:{conf['port']}"
                    
                    proxies.append(conf)
                    added_count += 1
                
                # HTTP/SOCKS5/MIXED
                elif ":" in line and ptype in ["http", "socks5", "mixed"]:
                    parts = line.split(":")
                    if len(parts) >= 2:
                        ip = parts[0].strip()
                        port = parts[1].strip()
                        
                        if not re.match(r"^\d+\.\d+\.\d+\.\d+$", ip):
                            skipped_invalid += 1
                            continue
                        
                        proto = ptype
                        if proto == "mixed":
                            proto = "http" if len(parts) == 2 else "socks5"
                        
                        if not self.ip_is_ir(ip):
                            skipped_non_iran += 1
                            continue
                        
                        self.logger.update_stat('iranian_proxies')
                        alive, ping = self.is_alive(ip, int(port))
                        
                        proxy_data = {
                            'name': f"{ip}:{port} ({ping}ms)" if alive else f"{ip}:{port}",
                            'type': proto,
                            'server': ip,
                            'port': int(port),
                            'added_date': datetime.now().strftime('%Y-%m-%d'),
                            'last_checked': datetime.now().strftime('%Y-%m-%d'),
                            'is_active': alive,
                            'country': 'IR',
                            'ping': ping if alive else 0,
                            'source': url,
                            'source_name': source_name
                        }
                        proxies.append(proxy_data)
                        added_count += 1
                    else:
                        skipped_invalid += 1
            
            except Exception:
                skipped_invalid += 1
                continue
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        current_total = self.logger.stats['total_proxies_received']
        current_iranian = self.logger.stats['iranian_proxies']
        self.logger.log(f"[{source_index}/{total_sources}] âœ… {source_name}: {added_count} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ", "INFO")
        self.logger.log(f"   ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ù†Ù‡Ø§ÛŒÛŒ: [{current_iranian}/{current_total}] | Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {skipped_invalid} | ØºÛŒØ±Ø§ÛŒØ±Ø§Ù†ÛŒ: {skipped_non_iran}", "DEBUG")
        
        return proxies
    
    def fetch_all_proxies(self) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù‡Ù…Ù‡ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹"""
        all_proxies = []
        seen_keys = set()
        
        total_sources = len(self.SOURCES)
        self.logger.log(f"\nğŸ“¥ Ø´Ø±ÙˆØ¹ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø§Ø² {total_sources} Ù…Ù†Ø¨Ø¹:")
        self.logger.log("=" * 70)
        
        for idx, (url, ptype, source_name) in enumerate(self.SOURCES, 1):
            proxies = self.fetch_source_proxies(url, ptype, source_name, idx, total_sources)
            
            # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§
            filtered_proxies = []
            for proxy in proxies:
                key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}-{proxy.get('type', '')}"
                if key not in seen_keys:
                    seen_keys.add(key)
                    filtered_proxies.append(proxy)
                else:
                    self.logger.update_stat('duplicates_found')
            
            all_proxies.extend(filtered_proxies)
            
            # ØªØ£Ø®ÛŒØ± Ø¨ÛŒÙ† Ù…Ù†Ø§Ø¨Ø¹
            if idx < total_sources:
                time.sleep(random.uniform(0.5, 1.5))
        
        self.logger.log("=" * 70)
        self.logger.log(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ {len(all_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø§Ø² {total_sources} Ù…Ù†Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
        return all_proxies
    
    def add_new_proxies(self, new_proxies: List[Dict[str, Any]]) -> Tuple[int, int]:
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù„ÛŒØ³Øª Ù…ÙˆØ¬ÙˆØ¯"""
        existing_keys = set()
        for proxy in self.config.get('proxies', []):
            key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}-{proxy.get('type', '')}"
            existing_keys.add(key)
        
        added_count = 0
        duplicate_count = 0
        
        for proxy in new_proxies:
            key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}-{proxy.get('type', '')}"
            if key not in existing_keys:
                self.config.setdefault('proxies', []).append(proxy)
                added_count += 1
                self.logger.update_stat('proxies_added')
            else:
                duplicate_count += 1
                self.logger.update_stat('duplicates_found')
        
        return added_count, duplicate_count
    
    def should_remove_old_proxies(self) -> Tuple[bool, List[Dict], int]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø±Ø§ÛŒØ· Ø­Ø°Ù Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
        total_proxies = len(self.config.get('proxies', []))
        
        if total_proxies <= 50:
            return False, [], 0
        
        excess_count = total_proxies - 50
        
        today = datetime.now()
        cutoff_date = today - timedelta(days=3)
        
        old_proxies = []
        for proxy in self.config.get('proxies', []):
            try:
                added_date = datetime.strptime(proxy['added_date'], '%Y-%m-%d')
                if added_date < cutoff_date:
                    old_proxies.append(proxy)
            except (ValueError, KeyError):
                continue
        
        old_proxies.sort(key=lambda x: datetime.strptime(x['added_date'], '%Y-%m-%d'))
        
        should_remove = len(old_proxies) > 0 and excess_count > 0
        
        return should_remove, old_proxies, excess_count
    
    def remove_old_proxies_with_conditions(self) -> int:
        """Ø­Ø°Ù Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±Ù‚Ø±Ø§Ø±ÛŒ Ø´Ø±Ø§ÛŒØ·"""
        should_remove, old_proxies, excess_count = self.should_remove_old_proxies()
        
        if not should_remove:
            return 0
        
        old_keys_to_remove = set()
        for proxy in old_proxies[:excess_count]:
            key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}-{proxy.get('type', '')}"
            old_keys_to_remove.add(key)
        
        remaining_proxies = []
        removed_count = 0
        
        for proxy in self.config.get('proxies', []):
            key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}-{proxy.get('type', '')}"
            
            if key in old_keys_to_remove and removed_count < excess_count:
                removed_count += 1
                self.logger.update_stat('proxies_removed')
                self.logger.log(f"   ğŸ—‘ï¸ Ø­Ø°Ù Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ: {proxy.get('server')}:{proxy.get('port')} (ØªØ§Ø±ÛŒØ®: {proxy.get('added_date')})", "INFO")
                continue
            
            remaining_proxies.append(proxy)
        
        self.config['proxies'] = remaining_proxies
        return removed_count
    
    def ensure_minimum_proxies(self):
        """Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø­Ø¯Ø§Ù‚Ù„ ÛµÛ° Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ø§Ù„"""
        active_proxies = [p for p in self.config.get('proxies', []) if p.get('is_active', False)]
        
        if len(active_proxies) >= 50:
            self.logger.log(f"âœ… {len(active_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª (Ú©Ø§ÙÛŒ Ø§Ø³Øª)")
            return
        
        needed = 50 - len(active_proxies)
        self.logger.log(f"âš ï¸ ÙÙ‚Ø· {len(active_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ø§Ù„ Ø¯Ø§Ø±ÛŒÙ…. Ù†ÛŒØ§Ø² Ø¨Ù‡ {needed} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨ÛŒØ´ØªØ±")
        
        self.logger.log("ğŸ” ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ...")
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ
        emergency_sources = [
            ("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=10000&country=all", "http", "emergency-http"),
            ("https://api.proxyscrape.com/v2/?request=displayproxies&protocol=socks5&timeout=10000&country=all", "socks5", "emergency-socks5"),
            ("https://raw.githubusercontent.com/freefq/free/master/v2", "vmess", "emergency-vmess"),
        ]
        
        original_sources = self.SOURCES.copy()
        self.SOURCES = emergency_sources
        
        new_emergency_proxies = self.fetch_all_proxies()
        added, _ = self.add_new_proxies(new_emergency_proxies)
        
        self.SOURCES = original_sources
        
        if added > 0:
            self.logger.log(f"âœ… {added} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")
        else:
            self.logger.log("âŒ Ù†ØªÙˆØ§Ù†Ø³ØªÛŒÙ… Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ø¶Ø§ÙÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒÙ…")
    
    def run(self) -> bool:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ"""
        self.logger.log("=" * 80)
        self.logger.log("ğŸš€ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ")
        self.logger.log(f"ğŸŒ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹: {len(self.SOURCES)} Ù…Ù†Ø¨Ø¹")
        self.logger.log("ğŸ” Ø³ÛŒØ³ØªÙ…: Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… IP Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø§ fallback")
        self.logger.log("=" * 80)
        
        try:
            # 1. ÙˆØ¶Ø¹ÛŒØª Ø§ÙˆÙ„ÛŒÙ‡
            initial_count = len(self.config.get('proxies', []))
            initial_active = len([p for p in self.config.get('proxies', []) 
                                 if p.get('is_active', False)])
            self.logger.log(f"ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ø§ÙˆÙ„ÛŒÙ‡:")
            self.logger.log(f"   â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§: {initial_count}")
            self.logger.log(f"   â€¢ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„: {initial_active}")
            self.logger.log(f"   â€¢ Ø­Ø¯Ø§Ù‚Ù„ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: 50")
            
            # 2. Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            new_proxies = self.fetch_all_proxies()
            self.logger.log(f"\nğŸ“¥ {len(new_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
            
            # 3. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            added_count, duplicate_count = self.add_new_proxies(new_proxies)
            self.logger.log(f"\nâ• Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯:")
            self.logger.log(f"   âœ… {added_count} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")
            if duplicate_count > 0:
                self.logger.log(f"   âš ï¸ {duplicate_count} Ù¾Ø±ÙˆÚ©Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯")
            
            # 4. Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø±Ø§ÛŒØ· Ø­Ø°Ù
            self.logger.log(f"\nğŸ—‘ï¸ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø±Ø§ÛŒØ· Ø­Ø°Ù Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ:")
            total_after_add = len(self.config.get('proxies', []))
            self.logger.log(f"   ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù†: {total_after_add}")
            
            should_remove, old_proxies, excess_count = self.should_remove_old_proxies()
            
            if should_remove:
                self.logger.log(f"   âœ“ Ø´Ø±Ø· Û±: ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ ({total_after_add}) > ÛµÛ°")
                self.logger.log(f"   âœ“ Ø´Ø±Ø· Û²: {len(old_proxies)} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² Û³ Ø±ÙˆØ²")
                self.logger.log(f"   âš¡ Ù‡Ø± Ø¯Ùˆ Ø´Ø±Ø· Ø¨Ø±Ù‚Ø±Ø§Ø± Ø§Ø³Øª â†’ Ø­Ø°Ù Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒÙ‡Ø§")
                
                removed_count = self.remove_old_proxies_with_conditions()
                if removed_count > 0:
                    self.logger.log(f"   âœ… {removed_count} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯")
            else:
                self.logger.log(f"   â¸ï¸ Ø´Ø±Ø§ÛŒØ· Ø­Ø°Ù Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª:")
                if total_after_add <= 50:
                    self.logger.log(f"     âœ— ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ({total_after_add}) â‰¤ ÛµÛ°")
                if len(old_proxies) == 0:
                    self.logger.log(f"     âœ— Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² Û³ Ø±ÙˆØ² ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            
            # 5. Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯
            self.logger.log(f"\nğŸ“Š Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒ...")
            self.ensure_minimum_proxies()
            
            # 6. Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
            self.logger.log(f"\nğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ ØªØºÛŒÛŒØ±Ø§Øª...")
            if not self.save_config():
                self.logger.log("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ!", "ERROR")
                return False
            
            # 7. Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ú©Ø§Ù…Ù„
            self.logger.print_stats()
            
            # 8. Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
            final_count = len(self.config.get('proxies', []))
            final_active = len([p for p in self.config.get('proxies', []) 
                               if p.get('is_active', False)])
            
            self.logger.log("\n" + "=" * 80)
            self.logger.log("ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ")
            self.logger.log("=" * 80)
            self.logger.log(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§: {final_count}")
            self.logger.log(f"âœ… Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„: {final_active}")
            self.logger.log(f"ğŸ“ˆ ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù„: {final_count - initial_count:+d} Ù¾Ø±ÙˆÚ©Ø³ÛŒ")
            self.logger.log(f"ğŸ“ˆ ØªØºÛŒÛŒØ±Ø§Øª ÙØ¹Ø§Ù„: {final_active - initial_active:+d} Ù¾Ø±ÙˆÚ©Ø³ÛŒ")
            
            # Ú¯Ø²Ø§Ø±Ø´ Ù…Ù†Ø§Ø¨Ø¹
            successful_sources = len(self.SOURCES) - len(self.failed_sources)
            self.logger.log(f"\nğŸŒ Ú¯Ø²Ø§Ø±Ø´ Ù…Ù†Ø§Ø¨Ø¹:")
            self.logger.log(f"   â€¢ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆÙÙ‚: {successful_sources}/{len(self.SOURCES)}")
            self.logger.log(f"   â€¢ Ù…Ù†Ø§Ø¨Ø¹ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù‡: {len(self.failed_sources)}")
            
            if final_active >= 50:
                self.logger.log(f"\nâœ… Ù…ÙˆÙÙ‚ÛŒØª: {final_active} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ ÙØ¹Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª")
            else:
                self.logger.log(f"\nâš ï¸ Ù‡Ø´Ø¯Ø§Ø±: ÙÙ‚Ø· {final_active} Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ ÙØ¹Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª")
            
            self.logger.log(f"\nğŸ“ ÙØ§ÛŒÙ„ Ù„Ø§Ú¯: {self.logger.log_file}")
            self.logger.log(f"ğŸ“ ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯: {self.config_path}")
            self.logger.log("=" * 80)
            
            return True
            
        except KeyboardInterrupt:
            self.logger.log("\n\nâ¹ï¸ Ø¹Ù…Ù„ÛŒØ§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯", "WARNING")
            return False
        except Exception as e:
            self.logger.log(f"\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}", "ERROR")
            import traceback
            self.logger.log(traceback.format_exc(), "ERROR")
            return False

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("ğŸ”§ Ù…Ø¯ÛŒØ± Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ - Ø³ÛŒØ³ØªÙ… Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… IP")
    print("ğŸ“… " + datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    print(f"ğŸŒ {len(IranProxyManager().SOURCES)} Ù…Ù†Ø¨Ø¹")
    print("ğŸ” Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø§ Ø³ÛŒØ³ØªÙ… fallback")
    
    manager = IranProxyManager()
    success = manager.run()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
